{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XP教師なし異常検知\n",
    "\n",
    "# k-means\n",
    "    k-means法は,データを適当なクラスタに分け,クラスタの平均を用いてデータを分け，クラスタリングするアルゴリズム.\n",
    "    任意のk個のクラスタを作成するアルゴリズムなので、k-means法(k点平均法)と呼ばれる.\n",
    "\n",
    "## 具体的な手順\n",
    "1. クラスタ数kを決める\n",
    "2. データが含まれる空間にランダムにk個の点(セントロイド)を置く\n",
    "3. 各データがセントロイドのうちどれに最も近いかを計算して、そのデータが所属するクラスタとする\n",
    "4. セントロイドの位置をそのクラスタに含まれるデータの重心になるように移動する\n",
    "5. 各セントロイドの重心が変わらなくなるまで3, 4を繰り返す\n",
    "\n",
    "## k-meansの問題点\n",
    "    ランダムな初期値に依存する．　-> 効率的にクラスタリングできない可能性がある．\n",
    "    \n",
    "----------------------------------------------------------------\n",
    "    \n",
    "# k-means++\n",
    "    初期のクラスター中心を確率的に遠く設置するという発想.\n",
    "    k-meansと異なる点は，セントロイドの初期値.\n",
    "   \n",
    "## 具体的な初期値決定手順\n",
    "\n",
    "1. 始めにデータ点をランダムに選び1つ目のセントロイドとする．\n",
    "2. 全てのデータ点とその最近傍のセントロイドの距離を求める．\n",
    "3. その距離の二乗に比例した確率で,選ばれていないデータ点をセントロイドとしてランダムに選ぶ．\n",
    "\n",
    "### 初期値が決まったのちは,通常のk-meansアルゴリズムを適用\n",
    "\n",
    "-------------------------------------------------------------------\n",
    "\n",
    "## XP手法\n",
    "    XPの教師なし異常検知では，シルエットプロットを用いて最適なクラスタ数を決定する．\n",
    "    測定したいFPGAそれぞれ，周波数を計測しk-meansを用いてクラスタリングしたのち，シルエットプロットで最適なクラスタ数を決定する．\n",
    "    この最適なクラスタ数が，新しいFPGAでは少なく，使用済みFPGAは多くなるという仮説のもと，実験を進める．\n",
    "    最適なクラスタ数を求めたのち，適切なクラスタ数閾値を設定して，使用済みFPGAを見分ける．\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"ライブラリ\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import seaborn as sns\n",
    "from statistics import mean, variance\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "from collections import Counter\n",
    "import copy\n",
    "\n",
    "class FPGA:\n",
    "    def __init__(self,frequency, cluster, center):\n",
    "        self.frequency = frequency\n",
    "        self.cluster = cluster\n",
    "        self.center = center\n",
    "\n",
    "\"\"\"データ生成関数\"\"\"\n",
    "def generate_data(directory, data_n, aged_data_n):\n",
    "    data = []\n",
    "    aged_data = []\n",
    "    \n",
    "    for i in range(1, data_n+1):\n",
    "        tmp_data = pd.read_csv(directory+'/s'+str(i)+'.csv', header=None).values\n",
    "        data.append(tmp_data)\n",
    "    \n",
    "    for i in range(1, aged_data_n+1):\n",
    "        tmp_data = pd.read_csv(directory+'/s'+str(i)+'_aged.csv', header=None).values\n",
    "        aged_data.append(tmp_data)\n",
    "    \n",
    "    data = np.array(data)\n",
    "    aged_data = np.array(aged_data)\n",
    "    \n",
    "    return data, aged_data\n",
    "\n",
    "newdata, ageddata = generate_data('fresh_aged_ieice', 50, 2)\n",
    "\n",
    "\n",
    "\"\"\"0の数数える関数 二次元入れろ\"\"\"\n",
    "def count_zero(data):\n",
    "    \n",
    "    tmp = []\n",
    "    for i in range(data.shape[0]):\n",
    "        a = (data[i].shape[0] * data[i].shape[1]) - np.count_nonzero(data[i])\n",
    "        tmp.append(a)\n",
    "        \n",
    "    return tmp\n",
    "\n",
    "\n",
    "\"\"\"一次元にする関数\"\"\"\n",
    "def change_flatten(data):\n",
    "    tmp = []\n",
    "    for i in range(data.shape[0]):\n",
    "        tmp.append(data[i].flatten())\n",
    "        \n",
    "    tmp = np.array(tmp)\n",
    "    \n",
    "    return tmp\n",
    "\n",
    "\n",
    "\"\"\"0を消す関数 flatteしたやつ入れろ\"\"\"\n",
    "def delete_zero(data):\n",
    "    tmp = []\n",
    "    for i in range(data.shape[0]):\n",
    "        tmp2 = copy.deepcopy(data[i])\n",
    "        tmp.append(tmp2[tmp2 != 0])\n",
    "        \n",
    "    tmp = np.array(tmp)\n",
    "    \n",
    "    return tmp\n",
    "\n",
    "\"\"\"９２０この値を消す\"\"\"\n",
    "def delete_920(data, check):\n",
    "    new = np.zeros_like(data)\n",
    "    counter = 0\n",
    "    for i in data:\n",
    "        for j in range(i.shape[0]):\n",
    "            for k in range(i.shape[1]):\n",
    "                if [j, k] in check:\n",
    "                    new[counter, j, k] = 0 \n",
    "                else:\n",
    "                    new[counter, j, k] = data[counter, j, k]\n",
    "                    \n",
    "        counter += 1\n",
    "                    \n",
    "    return new\n",
    "                    \n",
    "\n",
    "\"\"\"東西南北残差作り出す関数\"\"\"\n",
    "def EWSN_residual(data):\n",
    "    tmp_x = [0, 1, 0, -1]\n",
    "    tmp_y = [-1, 0, 1, 0]\n",
    "\n",
    "    residual_data = np.zeros_like(data)\n",
    "\n",
    "    for i in range(data.shape[0]):\n",
    "        for j in range(data[i].shape[0]):\n",
    "            for k in range(data[i].shape[1]):\n",
    "                if data[i, j, k] != 0:\n",
    "                    data_list = []\n",
    "                    for l in range(4):\n",
    "                        next_y = j + tmp_y[l]\n",
    "                        next_x = k + tmp_x[l]\n",
    "                        if 0 <= next_y < 148 and 0 <= next_x < 33 and data[i, next_y, next_x] != 0:\n",
    "                            data_list.append(data[i, next_y, next_x])\n",
    "    \n",
    "                    data_mean = mean(data_list)\n",
    "                    residual_data[i, j, k] = np.abs(data[i, j, k] - data_mean)\n",
    "\n",
    "    return residual_data\n",
    "\n",
    "\n",
    "\"\"\"king残差作り出す関数\"\"\"\n",
    "def king_residual(data):\n",
    "    tmp_x = [-1, 0, 1, 1, 1, 0, -1, -1]\n",
    "    tmp_y = [-1, -1, -1, 0, 1, 1, 1, 0]\n",
    "    \n",
    "    residual_data = np.zeros_like(data)\n",
    "    \n",
    "    for i in range(data.shape[0]):\n",
    "        for j in range(data[i].shape[0]):\n",
    "            for k in range(data[i].shape[1]):\n",
    "                if data[i, j, k] != 0:\n",
    "                    data_list = []\n",
    "                    for l in range(8):\n",
    "                        next_y = j + tmp_y[l]\n",
    "                        next_x = k + tmp_x[l]\n",
    "                        if 0 <= next_y < 148 and 0 <= next_x < 33 and data[i, next_y, next_x] != 0:\n",
    "                            data_list.append(data[i, next_y, next_x])\n",
    "    \n",
    "                    data_mean = mean(data_list)\n",
    "                    residual_data[i, j, k] = np.abs(data[i, j, k] - data_mean)\n",
    "\n",
    "    return residual_data\n",
    "\n",
    "    \n",
    "\"\"\"リストを繋げる関数\"\"\"\n",
    "def connect(a, b):\n",
    "    tmp = []\n",
    "    for i in range(a.shape[0]):\n",
    "        tmp.append(a[i])\n",
    "        \n",
    "    for i in range(b.shape[0]):\n",
    "        tmp.append(b[i])\n",
    "    \n",
    "    tmp = np.array(tmp)\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "fresh, aged = generate_data('fresh_aged_ieice', 50, 2) # (50, 148, 33) (2, 148, 33)\n",
    "\n",
    "newdata = connect(fresh, aged) # (52, 148, 33)\n",
    "check_FPGA = []\n",
    "for i in range(148):\n",
    "    for j in range(33):\n",
    "        if fresh[0, i, j] == 0:\n",
    "            check_FPGA.append([i,j])\n",
    "freshaged = delete_920(newdata, check_FPGA) #(52, 148, 33)\n",
    "\n",
    "flat_freshaged = change_flatten(newdata) # (52, 4884)\n",
    "new_freshaged = change_flatten(freshaged) # (52 4884)\n",
    "\n",
    "new_nonzero = delete_zero(flat_freshaged) #(52, 3964前後)\n",
    "nonzero_freshaged = delete_zero(new_freshaged) #(52, 3964)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_plus_plus(data, cluster_num):\n",
    "    \"\"\"\n",
    "    中心点ゲット！\n",
    "    \"\"\"\n",
    "    \n",
    "    seeds = 50\n",
    "    np.random.seed(seeds)\n",
    "\n",
    "    # data_num = data.shape[0]\n",
    "    feature_num = data.shape[0]\n",
    "\n",
    "    centers = np.zeros(cluster_num)\n",
    "    distance = np.zeros(cluster_num)\n",
    "\n",
    "    probability = np.repeat(1/feature_num, feature_num)\n",
    "    centers[0] = np.random.choice(data, 1, p=probability)\n",
    "    distance[0] = np.sum((abs(data - centers[0]))**2)\n",
    "\n",
    "    for k in range(1, cluster_num):\n",
    "        np.random.seed(seeds*(k+1))\n",
    "        probability = data / np.sum(distance)\n",
    "        probability /= probability.sum() #正規化　probabilities do not sum to 1　と怒られたから\n",
    "\n",
    "        centers[k] = np.random.choice(data, 1, p=probability)\n",
    "        distance[k] = np.sum((abs(data - centers[k]))**2)\n",
    "\n",
    "    return centers\n",
    "\n",
    "\n",
    "def wrap_k_means(data, k=3):\n",
    "    cluster = kmeans_plus_plus(data, k) # 初期値kmeans++\n",
    "    prof, cluster = k_means(data, cluster)\n",
    "    return prof, cluster\n",
    "\n",
    "\n",
    "def k_means(data, cluster):\n",
    "    data = np.array(data, dtype=float)\n",
    "    prof = np.zeros(len(data)) # 各要素∈dataがどのクラスタに属しているか\n",
    "    cluster = np.sort(np.array(cluster, dtype=float))\n",
    "    old_cluster = np.zeros(len(cluster)) # 収束チェック用\n",
    "    \n",
    "    conv = True; count = 0\n",
    "    while conv:\n",
    "        count += 1\n",
    "        \n",
    "        # 割り当て\n",
    "        for i,d in enumerate(data):\n",
    "            min_d = float('inf')# てきとうに大きい数\n",
    "            for j,c in enumerate(cluster):\n",
    "                dist = (abs(d - c))**2\n",
    "                if min_d > dist:\n",
    "                    min_d = dist\n",
    "                    prof[i] = j # クラスタの割り当て\n",
    "\n",
    "        # 更新\n",
    "        for j,c in enumerate(cluster):\n",
    "            m = 0; n = 0\n",
    "            for i,p in enumerate(prof):\n",
    "                if p == j: # もしもそのクラスタに属していたら\n",
    "                    m += data[i]\n",
    "                    n += 1\n",
    "            if m != 0:\n",
    "                m /= n # mは更新した平均\n",
    "                old_cluster[j] = cluster[j]\n",
    "                cluster[j] = m\n",
    "            \n",
    "        # 収束チェック\n",
    "        for i,c in enumerate(cluster):\n",
    "            if c != old_cluster[i]:\n",
    "                conv = True\n",
    "                break\n",
    "            else:\n",
    "                conv = False\n",
    "\n",
    "    return prof, cluster\n",
    "\n",
    "\n",
    "def choose_center(i, x, tmp_list):\n",
    "    tmp = []\n",
    "    for j in range(len(i.center)):\n",
    "        if j != x:\n",
    "            tmp_list2 = []\n",
    "            for k in range(len(i.frequency)):\n",
    "                if i.cluster[k] == j:\n",
    "                    tmp_list2.append(i.frequency[k])\n",
    "            tmp.append(tmp_list2)\n",
    "\n",
    "    tmp = np.array(tmp)\n",
    "\n",
    "    nci_list = []\n",
    "    for k in tmp:\n",
    "        average_list = []\n",
    "        for j in tmp_list:\n",
    "            nci = np.sum(abs(k - j)) / len(k)\n",
    "            average_list.append(nci)\n",
    "\n",
    "        average_list = np.array(average_list)\n",
    "        average_mean = np.mean(average_list)\n",
    "\n",
    "        nci_list.append(average_mean)\n",
    "\n",
    "    nci_list = np.array(nci_list)\n",
    "\n",
    "    a = np.argmin(nci_list)\n",
    "\n",
    "    return tmp[a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    fresh, aged = generate_data('fresh_aged_ieice', 50, 2) # (50, 148, 33) (2, 148, 33)\n",
    "    freshaged = connect(fresh, aged) # (52, 148, 33)\n",
    "    flat_freshaged = change_flatten(freshaged) # (52, 4884)\n",
    "    nonzero_freshaged = delete_zero(flat_freshaged) #(52, 3964前後)\n",
    "\n",
    "    every_cluster_list = [] # (7, 52)\n",
    "    for x in range(2, 9):\n",
    "\n",
    "        fpga_class = []\n",
    "        for i in range(nonzero_freshaged.shape[0]):\n",
    "            prof, cluster = wrap_k_means(nonzero_freshaged[i], x)\n",
    "            #print(f'{i}回目')\n",
    "            tmp = FPGA(nonzero_freshaged[i], prof, cluster)\n",
    "            fpga_class.append(tmp)\n",
    "\n",
    "        # frequency, cluster, center\n",
    "        x_cluster_list = [] #(52)\n",
    "        counter = 0\n",
    "        for i in fpga_class:\n",
    "            num = len(i.center)\n",
    "            sci_mean_list = [] #(num)\n",
    "            for j in range(num):\n",
    "\n",
    "                tmp_list = [] \n",
    "                for k in range(len(i.frequency)):\n",
    "                    if i.cluster[k] == j:\n",
    "                        tmp_list.append(i.frequency[k])\n",
    "                tmp_list = np.array(tmp_list)\n",
    "\n",
    "                tmp_list2 = choose_center(i, j, tmp_list)\n",
    "\n",
    "                #シルエットプロット計算\n",
    "                sci_list = [] \n",
    "                for k in tmp_list:\n",
    "                    oci = np.sum(abs(tmp_list - k)) / (len(tmp_list) - 1)\n",
    "                    nci = np.sum(abs(tmp_list2 - k)) / len(tmp_list2)\n",
    "                    sci = (nci - oci) / max(nci, oci)\n",
    "                    sci_list.append(sci)\n",
    "\n",
    "                sci_list = np.array(sci_list)\n",
    "                sci_mean = np.mean(sci_list)\n",
    "                sci_mean_list.append(sci_mean)\n",
    "\n",
    "            sci_mean_list = np.array(sci_mean_list)\n",
    "            sci_mean_mean_list = np.mean(sci_mean_list)\n",
    "            x_cluster_list.append(sci_mean_mean_list)\n",
    "            #print(f'{counter}回目')\n",
    "            counter += 1\n",
    "\n",
    "        every_cluster_list.append(x_cluster_list)\n",
    "        print(f'{x}回目')\n",
    "\n",
    "    f = open('ACN_list_4.binaryfile', 'wb')\n",
    "    pickle.dump(every_cluster_list, f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "Ran out of input",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-29022422e794>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ACN_list_4.binaryfile'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0maged_acn_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEOFError\u001b[0m: Ran out of input"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "f = open('ACN_list_4.binaryfile', 'rb') \n",
    "aged_acn_list = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "aged_acn_list = np.array(aged_acn_list)\n",
    "aged_acn_list= aged_acn_list.T\n",
    "\n",
    "index_list = np.arange(1, 53)\n",
    "acn_list = []\n",
    "average_list = []\n",
    "status_list = []\n",
    "for x in aged_acn_list:\n",
    "    acn = 0\n",
    "    tmp = 0\n",
    "    for i in range(len(x)):\n",
    "        if tmp < x[i]:\n",
    "            tmp = x[i]\n",
    "            acn = i + 2\n",
    "\n",
    "    average_list.append(tmp)\n",
    "    acn_list.append(acn)\n",
    "\n",
    "for i in range(50):\n",
    "    status_list.append('unused')\n",
    "for i in range(2):\n",
    "    status_list.append('aged')\n",
    "\n",
    "print(acn_list)\n",
    "print(len(acn_list))\n",
    "\n",
    "test = [average_list, acn_list, status_list]\n",
    "test = np.array(test)\n",
    "test = test.T\n",
    "df = pd.DataFrame(test,\n",
    "                  columns=['Maximum Average Silhouette value', 'Appropriate Cluster Number', 'Status'],\n",
    "                  index=index_list)\n",
    "\n",
    "print(df)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
